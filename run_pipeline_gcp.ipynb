{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DTMCQnChfDVM",
      "metadata": {
        "executionInfo": {
          "elapsed": 11006,
          "status": "ok",
          "timestamp": 1715315615868,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 420
        },
        "id": "DTMCQnChfDVM"
      },
      "outputs": [],
      "source": [
        "! pip install -Uqq requests PyYAML google-cloud-aiplatform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_DOUWYM4T3dF",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 9,
          "status": "ok",
          "timestamp": 1715315615868,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 420
        },
        "id": "_DOUWYM4T3dF",
        "outputId": "8b73a02a-ce03-44f8-b718-1e86a6669424"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# Directory where you want to clone the repository\n",
        "repo_dir = 'gretel-mlops'\n",
        "\n",
        "# Check if the directory exists\n",
        "if not os.path.exists(repo_dir):\n",
        "    # Directory does not exist, clone the repository\n",
        "    !git clone https://github.com/gretelai/gretel-mlops.git\n",
        "else:\n",
        "    print(f\"The directory '{repo_dir}' already exists.\")\n",
        "\n",
        "# Import Gretel MLOps modules\n",
        "gretel_mlops_path = os.getcwd() + \"/gretel-mlops/src/\"\n",
        "if gretel_mlops_path not in sys.path:\n",
        "    sys.path.append(gretel_mlops_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FwX0UBHsZESl",
      "metadata": {
        "executionInfo": {
          "elapsed": 2686,
          "status": "ok",
          "timestamp": 1715315618546,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 420
        },
        "id": "FwX0UBHsZESl"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import json\n",
        "\n",
        "from google.cloud import aiplatform as aip\n",
        "from google.colab import auth\n",
        "from kfp import compiler\n",
        "from gretel_mlops.gcp.vertexai.pipeline import (\n",
        "    create_pipeline,\n",
        "    get_pipeline_job_result,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9aHCalcsZM77",
      "metadata": {
        "id": "9aHCalcsZM77"
      },
      "source": [
        "## 1. Setup and Configuration for Vertex AI and GCP Services\n",
        "\n",
        "- **Project and Region Setup**: Sets up the `PROJECT_ID` and `REGION` for the Vertex AI project. Defines the `BUCKET_URI` for Google Cloud Storage.\n",
        "- **User Authentication**: Executes commands to authenticate the user's Google Cloud account, ensuring secure access to GCP services.\n",
        "- **Bucket Creation**: Creates a new Google Cloud Storage bucket designated by `BUCKET_URI`, used for storing pipeline artifacts and data.\n",
        "- **Service Account Retrieval**: Retrieves the project number and constructs the service account email. This service account will be used for operations within Vertex AI.\n",
        "- **Service Account Permission Configuration**: Assigns necessary roles to the service account for object creation and viewing in the storage bucket. Ensures the service account has the required permissions for smooth operation.\n",
        "- **Secret Manager Access**: Grants the service account access to the Secret Manager, allowing it to handle secrets, such as API keys, needed for secure operations.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WLppT1j-1lk1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 111117,
          "status": "ok",
          "timestamp": 1715315729661,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 420
        },
        "id": "WLppT1j-1lk1",
        "outputId": "06ca55aa-8316-4db9-c767-254e2af42c96"
      },
      "outputs": [],
      "source": [
        "# GCP Configuration\n",
        "PROJECT_ID = \"gretel-eng-sandbox\"  # @param {type:\"string\"}\n",
        "REGION = \"us-central1\"  # @param {type: \"string\"}\n",
        "BUCKET_URI = f\"gs://{PROJECT_ID}-vertex-pipeline\"\n",
        "GRETEL_SECRET_NAME = \"GretelApiKey\" # @param {type: \"string\"}\n",
        "\n",
        "# Set the project id\n",
        "! gcloud config set project {PROJECT_ID}\n",
        "\n",
        "# Authenticate your Google Cloud account\n",
        "! gcloud auth login --no-launch-browser\n",
        "\n",
        "# Authenticate\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Create bucket\n",
        "! gsutil mb -l {REGION} -p {PROJECT_ID} {BUCKET_URI}\n",
        "\n",
        "# Retrieve service account\n",
        "shell_output = ! gcloud projects describe $PROJECT_ID\n",
        "PROJECT_NUMBER = shell_output[-1].split(\":\")[1].strip().replace(\"'\", \"\")\n",
        "SERVICE_ACCOUNT = f\"{PROJECT_NUMBER}-compute@developer.gserviceaccount.com\"\n",
        "\n",
        "# Set service account for Vertex AI Pipelines\n",
        "! gsutil iam ch serviceAccount:{SERVICE_ACCOUNT}:roles/storage.objectCreator $BUCKET_URI\n",
        "! gsutil iam ch serviceAccount:{SERVICE_ACCOUNT}:roles/storage.objectViewer $BUCKET_URI\n",
        "\n",
        "# Grant Secret Manager Access to Service Account\n",
        "! gcloud projects add-iam-policy-binding {PROJECT_ID} \\\n",
        "  --member=\"serviceAccount:{SERVICE_ACCOUNT}\" \\\n",
        "  --role=\"roles/secretmanager.secretAccessor\" \\\n",
        "  --condition=None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qOne3FR3Zr4h",
      "metadata": {
        "id": "qOne3FR3Zr4h"
      },
      "source": [
        "## 2. Fetch and load Gretel MLOps configuration from a YAML file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6tctMDoR11lq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 11,
          "status": "ok",
          "timestamp": 1715315729661,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 420
        },
        "id": "6tctMDoR11lq",
        "outputId": "a173bd19-10cc-4561-a2e4-be1ec6b19e97"
      },
      "outputs": [],
      "source": [
        "import yaml\n",
        "\n",
        "# URL of the raw YAML file\n",
        "config_path = \"gretel-mlops/configs/config_stroke.yaml\"\n",
        "\n",
        "# Open the YAML file and get the content\n",
        "with open(config_path, 'r') as file:\n",
        "    config_dict = yaml.safe_load(file)\n",
        "\n",
        "# Note uncomment below lines for Gretel Hybrid usage\n",
        "# config_dict['gretel']['mode'] = 'hybrid'\n",
        "# config_dict['gretel']['sink_bucket'] = 'gretel-hybrid-sandbox-sink' # your sink bucket name\n",
        "\n",
        "# view config\n",
        "yaml.dump(config_dict, sys.stdout, default_flow_style=False, sort_keys=False)\n",
        "\n",
        "config = json.dumps(config_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MAHDpocZZ7Bl",
      "metadata": {
        "id": "MAHDpocZZ7Bl"
      },
      "source": [
        "## 3. Build the pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6iJ_9RpE1rED",
      "metadata": {
        "executionInfo": {
          "elapsed": 1,
          "status": "ok",
          "timestamp": 1715315729661,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 420
        },
        "id": "6iJ_9RpE1rED"
      },
      "outputs": [],
      "source": [
        "# Initialize the Vertex AI SDK for Python for the project and bucket.\n",
        "aip.init(project=PROJECT_ID, staging_bucket=BUCKET_URI)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eQZc7F_u16qg",
      "metadata": {
        "executionInfo": {
          "elapsed": 179,
          "status": "ok",
          "timestamp": 1715315729839,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 420
        },
        "id": "eQZc7F_u16qg"
      },
      "outputs": [],
      "source": [
        "# Create the pipeline\n",
        "\n",
        "PIPELINE_NAME = \"gretel-vertex-mlops-pipeline\"  # @param {type: \"string\"}\n",
        "MODEL_NAME = f\"gretel-model-{config_dict['dataset']['name']}\"\n",
        "MODEL_IMAGE = \"us-docker.pkg.dev/vertex-ai/training/xgboost-cpu.1-6:latest\"\n",
        "PIPELINE_ROOT = \"{}/pipeline_root/control\".format(BUCKET_URI)\n",
        "\n",
        "pipeline = create_pipeline(\n",
        "    PIPELINE_NAME,\n",
        "    PIPELINE_ROOT,\n",
        "    MODEL_NAME,\n",
        "    MODEL_IMAGE,\n",
        "    PROJECT_ID,\n",
        "    REGION,\n",
        "    GRETEL_SECRET_NAME,\n",
        "    PROJECT_NUMBER,\n",
        "    config,\n",
        ")\n",
        "\n",
        "# compile the pipeline\n",
        "compiler.Compiler().compile(\n",
        "    pipeline_func=pipeline, package_path=f\"{PIPELINE_NAME}.yaml\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Ou0yxhXYaOIp",
      "metadata": {
        "id": "Ou0yxhXYaOIp"
      },
      "source": [
        "## 4. Submit the pipeline job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iOdmNC6B1_-J",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOdmNC6B1_-J",
        "outputId": "da20b855-17b0-4cbc-d197-4392dbba6d13"
      },
      "outputs": [],
      "source": [
        "# Run the pipeline\n",
        "\n",
        "job = aip.PipelineJob(\n",
        "    display_name=PIPELINE_NAME,\n",
        "    template_path=f\"{PIPELINE_NAME}.yaml\",\n",
        "    pipeline_root=PIPELINE_ROOT,\n",
        ")\n",
        "\n",
        "job.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DdQXtXgraTIs",
      "metadata": {
        "id": "DdQXtXgraTIs"
      },
      "source": [
        "## 5. Inspect Evaluation Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ygBOULxi2CQb",
      "metadata": {
        "id": "ygBOULxi2CQb"
      },
      "outputs": [],
      "source": [
        "# Show Evaluation report\n",
        "\n",
        "evaluation_report = get_pipeline_job_result(\n",
        "    job_name=job.resource_name, project=PROJECT_ID, location=REGION\n",
        ")\n",
        "\n",
        "print(\"Evaluation metrics:\")\n",
        "print(evaluation_report)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "run_pipeline_gcp.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
